{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# import Unity environment and turn off graphic during training\n",
    "from unityagents import UnityEnvironment\n",
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\", no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of agents, action size, state size and initial state for training\n",
    "num_agent = len(env_info.agents)\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "action_size = brain.vector_action_space_size\n",
    "\n",
    "# initialize the DDPG agents with action size, action size and number of agents \n",
    "from maddpg import MMDDPG\n",
    "m_agents = MMDDPG(state_size, action_size, num_agent, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddpg_train(n_episodes=6000, max_t=1000, print_every=100):\n",
    "\n",
    "    # keep track of the last 100 scores\n",
    "    ave_scores_deque_x = deque(maxlen=100)\n",
    "    ave_scores_deque_y = deque(maxlen=100)\n",
    "    max_scores_deque = deque(maxlen=100)\n",
    "    max_scores = []\n",
    "    \n",
    "    last_n_actions_deque = deque(maxlen=100)\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "           \n",
    "        # at the beginning of each episode, reset environment, state and score\n",
    "        # set train mode to True during training\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agent)\n",
    "\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            # for each step:\n",
    "            # 1) after observing a state at time t, agent takes action per current policy \n",
    "            # 2) after taking action at time t, agent oberves state and reward at t+1\n",
    "            # 3) agent then adds the \"SARS\" tuple to memory \n",
    "            # 4) at every UPDATE_EVERY steps, agent then randomly select a batch of memory to update \n",
    "            #    parameters of its value fuction and policy function by using by DDPG \n",
    "           \n",
    "            actions = m_agents.act(states)\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            m_agents.step(states, actions, rewards, next_states, dones)\n",
    "           \n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        \n",
    "        ave_scores_deque_x.append(scores[0])\n",
    "        ave_scores_deque_y.append(scores[1])\n",
    "        max_scores_deque.append(scores)\n",
    "        max_scores.append(np.max(scores))\n",
    "            \n",
    "        if i_episode % print_every == 0:\n",
    "            #print(np.mean(max_scores_deque, axis=0))\n",
    "            print('\\rEpisode {}\\tAverage Max Score: {:.4f}\\tBest Max Score: {:.4f}\\tAverage Score by Agent: {:.4f}, {:.4f}'\n",
    "                  .format(i_episode, np.mean(max_scores_deque), np.max(max_scores_deque), np.mean(ave_scores_deque_x), np.mean(ave_scores_deque_y)))\n",
    "            \n",
    "        # save weights of parameters when average reward (over 100 episodes) reaches at least 30\n",
    "        if np.mean(max_scores_deque) >= 0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, np.mean(max_scores_deque)))\n",
    "            for i, agent in enumerate(m_agents.agents):\n",
    "                torch.save(agent.actor_local.state_dict(), 'checkpoint_' + str(i) + '_actor.pth')\n",
    "                torch.save(agent.critic_local.state_dict(), 'checkpoint_' + str(i) + '_crtitc.pth')\n",
    "            break\n",
    "               \n",
    "    return max_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\Documents\\GitHub\\deep-reinforcement-learning\\p3_collab-compet\\maddpg.py:135: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(agent.critic_local.parameters(), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Max Score: -0.0050\tBest Max Score: 0.0000\tAverage Score by Agent: -0.0035, -0.0065\n",
      "Episode 200\tAverage Max Score: -0.0050\tBest Max Score: 0.0000\tAverage Score by Agent: -0.0050, -0.0050\n",
      "Episode 300\tAverage Max Score: -0.0050\tBest Max Score: 0.0000\tAverage Score by Agent: -0.0038, -0.0062\n",
      "Episode 400\tAverage Max Score: 0.0020\tBest Max Score: 0.2000\tAverage Score by Agent: 0.0014, 0.0026\n",
      "Episode 500\tAverage Max Score: -0.0010\tBest Max Score: 0.1000\tAverage Score by Agent: -0.0031, 0.0011\n",
      "Episode 600\tAverage Max Score: 0.0130\tBest Max Score: 0.1000\tAverage Score by Agent: -0.0055, 0.0315\n",
      "Episode 700\tAverage Max Score: 0.0010\tBest Max Score: 0.1000\tAverage Score by Agent: 0.0026, -0.0006\n",
      "Episode 800\tAverage Max Score: 0.0045\tBest Max Score: 0.2000\tAverage Score by Agent: -0.0003, 0.0093\n",
      "Episode 900\tAverage Max Score: 0.0090\tBest Max Score: 0.1000\tAverage Score by Agent: 0.0051, 0.0129\n",
      "Episode 1000\tAverage Max Score: 0.0245\tBest Max Score: 0.2900\tAverage Score by Agent: 0.0017, 0.0473\n",
      "Episode 1100\tAverage Max Score: 0.0120\tBest Max Score: 0.2000\tAverage Score by Agent: 0.0055, 0.0185\n",
      "Episode 1200\tAverage Max Score: 0.0320\tBest Max Score: 0.2000\tAverage Score by Agent: 0.0560, 0.0080\n",
      "Episode 1300\tAverage Max Score: 0.0425\tBest Max Score: 0.2000\tAverage Score by Agent: 0.0554, 0.0295\n",
      "Episode 1400\tAverage Max Score: 0.0425\tBest Max Score: 0.1000\tAverage Score by Agent: 0.0428, 0.0422\n",
      "Episode 1500\tAverage Max Score: 0.0225\tBest Max Score: 0.1000\tAverage Score by Agent: 0.0079, 0.0371\n",
      "Episode 1600\tAverage Max Score: 0.0375\tBest Max Score: 0.2000\tAverage Score by Agent: 0.0330, 0.0420\n",
      "Episode 1700\tAverage Max Score: 0.0620\tBest Max Score: 0.3000\tAverage Score by Agent: 0.0625, 0.0615\n",
      "Episode 1800\tAverage Max Score: 0.0685\tBest Max Score: 0.4000\tAverage Score by Agent: 0.0681, 0.0689\n",
      "Episode 1900\tAverage Max Score: 0.0955\tBest Max Score: 0.3000\tAverage Score by Agent: 0.1097, 0.0813\n",
      "Episode 2000\tAverage Max Score: 0.0760\tBest Max Score: 0.3000\tAverage Score by Agent: 0.0843, 0.0677\n",
      "Episode 2100\tAverage Max Score: 0.0830\tBest Max Score: 0.3000\tAverage Score by Agent: 0.1059, 0.0600\n",
      "Episode 2200\tAverage Max Score: 0.1085\tBest Max Score: 0.5000\tAverage Score by Agent: 0.1213, 0.0957\n",
      "Episode 2300\tAverage Max Score: 0.2896\tBest Max Score: 2.6000\tAverage Score by Agent: 0.2942, 0.2849\n",
      "\n",
      "Environment solved in 2340 episodes!\tAverage Score: 0.5016\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUXHWd9/H3t5d09oXsQEKzRDAgEGgQRBwU2ZGMyiPgAoOOeRQQcWYeB1BZPHpgfBxwEIYdBeGwCYb4JAECRAgjCemE7GsTspF9687W6e37/FG3LtXV1Wvq1taf1zl9uureX9/7rdtV91u/5f6uuTsiIiIARdkOQEREcoeSgoiIhJQUREQkpKQgIiIhJQUREQkpKYiISEhJQUREQkoKIiISUlIQEZFQSbYD6KwhQ4Z4eXl5tsMQEckrc+bM2ebuQ9srl3dJoby8nMrKymyHISKSV8xsTUfKqflIRERCSgoiIhJSUhARkZCSgoiIhJQUREQkpKQgIiIhJQUREQkpKYiIZFldQxMvVK4j8fbI7324naote3ixch219Y0ZiyXvLl4TESk097+1kvveqqJXaTFfOelQAK56dGa4fsXm3fzskrEZiUU1BRGRLNu6pw6Amtr6lOu3BeszQUlBRERCSgoiIhKKLCmY2Sgzm25mS81ssZn9OEWZc8ys2szmBT+3RRWPiEi+sgzuK8qO5gbgX919rpn1A+aY2TR3X5JUboa7XxphHCIi0kGR1RTcfaO7zw0e7waWAodFtT8RETl4GelTMLNyYBwwK8XqM81svplNNbPjMxGPiIikFvl1CmbWF3gJuMnda5JWzwWOcPc9ZnYxMBEYk2IbE4AJAKNHj444YhGR7ivSmoKZlRJLCM+4+8vJ6929xt33BI+nAKVmNiRFuUfcvcLdK4YObfduciIihSWDPc1Rjj4y4HFgqbvf00qZEUE5zOz0IJ7tUcUkIiJti7L56CzgO8BCM5sXLLsVGA3g7g8BlwM/NLMGYD9wpSdO/iEiIhkVWVJw93dpp9Lj7vcD90cVg4iIdI6uaBYRkZCSgoiIhJQURERynGVw+JGSgoiIhJQUREQkpKQgIiIhJQUREQkpKYiISEhJQUQkx1khzH0kIiL5R0lBRERCSgoiIhJSUhARkZCSgohIjstgP7OSgoiIfEJJQUREQkoKIiISUlIQEckhtfWNlN88udmyF+es53N3vZmR/SspiIjkkN21DSmXb6iuzcj+lRRERCSkpCAiIiElBRERCSkpiIhISElBRERCSgoiIlm2cvPubIcQUlIQEcmyyjU7sx1CSElBRERCSgoiIhJSUhARkVBkScHMRpnZdDNbamaLzezHKcqYmd1nZlVmtsDMTokqHhERaV9JhNtuAP7V3eeaWT9gjplNc/clCWUuAsYEP58FHgx+i4h0S45ndf+R1RTcfaO7zw0e7waWAoclFRsPPOUxM4GBZjYyqphERKRtUdYUQmZWDowDZiWtOgxYl/B8fbBsYybiEhHJpgemVzF/3a5myyyjN99sKfKkYGZ9gZeAm9y9Jnl1ij9pUXcyswnABIDRo0enPUYRkWz4v68tz3YILUQ6+sjMSoklhGfc/eUURdYDoxKeHw5sSC7k7o+4e4W7VwwdOjSaYEVEJNLRRwY8Dix193taKTYJuDoYhXQGUO3uajoSkW4r2x3NUTYfnQV8B1hoZvOCZbcCowHc/SFgCnAxUAXsA66NMB4REWlHZEnB3d8ldZ9BYhkHro8qBhGRfJPtjmZd0SwiIiElBRGRHJLtPgUlBRERCSkpiIjkEPUpiIhIzlBSEBHJIepTEBGRnKGkICIiISUFEZEcoo5mERHJGUoKIiI5RB3NIiKSM5QURERyiPoUREQkZygpiIjkEPUpiIhIzlBSEBGRkJKCiEgOUUeziIjkDCUFEZEcoo5mERHJGUoKIiISUlIQEckh6mgWEZGQ+hRERCRnKCmIiEhISUFEJIeoT0FERELqUxARkZwRWVIwsyfMbIuZLWpl/TlmVm1m84Kf26KKRUREOqYkwm3/EbgfeKqNMjPc/dIIYxARkU6IrKbg7u8AO6LavohIIeruHc1nmtl8M5tqZsdnORYRkaxrq6N5d2195PvPZlKYCxzh7icBvwcmtlbQzCaYWaWZVW7dujVjAYqI5JK5a3dFvo+sJQV3r3H3PcHjKUCpmQ1ppewj7l7h7hVDhw7NaJwiIrkiEw1LWUsKZjbCzCx4fHoQy/ZsxSMikussA1mhw6OPzOzzwBh3/4OZDQX6uvtHbZR/FjgHGGJm64HbgVIAd38IuBz4oZk1APuBK909u1dtiIhkW5bPgh1KCmZ2O1ABHAv8gdjJ/WngrNb+xt2vamub7n4/sSGrIiLSAZkYmdTR5qOvApcBewHcfQPQL6qgREQkOzqaFOqCph0HMLM+0YUkIiKpZKJPoaNJ4QUzexgYaGbfB94AHo0uLBGR7inbHasd6lNw99+a2XlADbF+hdvcfVqkkYmISDOZGJLablIws2LgNXf/MqBEICJSwNptPnL3RmCfmQ3IQDwiItIKy0CnQkevU6gFFprZNIIRSADufmMkUYmISAu5dPHa5OBHREQilO1LeDva0fykmfUAPhUsWu7u0U/XJyIioZzoaIbYXdKAJ4HVxOIaZWbXBPdMEBGRAtHR5qP/BM539+UAZvYp4Fng1KgCExGR5jLR0dzRi9dK4wkBwN1XEExuJyIi6dPWTXYyoaM1hUozexz4U/D8W8CcaEISEZFUcmn00Q+B64EbifUpvAP8d1RBiYhIdnQ0KZQA/+Xu90B4lXNZZFGJiEgLuXTntTeBXgnPexGbFE9ERApIR5NCz/j9lAGCx72jCUlEpPtq6+K1XBp9tNfMTok/MbMKYrfQFBGRDMmljuabgBfNbAOx6b4PBa6ILCoREcmKNmsKZnaamY1w99nAccDzQAPwKvBRBuITEZFALnQ0PwzUBY/PBG4FHgB2Ao9EGJeISLeU63deK3b3HcHjK4BH3P0l4CUzmxdtaCIikigXOpqLzSyeOM4F3kpY19H+CBERyRPtndifBd42s23ERhvNADCzY4DqiGMTEZEEWZ86291/bWZvAiOB193DEbRFwI+iDk5EpLvxLN9lp90mIHefmWLZimjCERGR1mTiOoWOXrwmIiJZZhloQFJSEBGRkJKCiIiEIksKZvaEmW0xs0WtrDczu8/MqsxsQeLcSiIi3VWW+5kjrSn8EbiwjfUXAWOCnwnAgxHGIiKS9zJxq87IkoK7vwPsaKPIeOApj5kJDDSzkVHFIyIi7cvmVcmHAesSnq8Plm3MTjgiItn129eW8+7Kba2uz0TTUjY7mlONrUr5ks1sgplVmlnl1q1bIw5LRCQ7du6rZ+qiTVmNIZtJYT0wKuH54cCGVAXd/RF3r3D3iqFDh2YkOBGR7iibSWEScHUwCukMoNrd1XQkItKKTAxMiqxPwcyeBc4BhpjZeuB2oBTA3R8CpgAXA1XAPuDaqGIREZGOiSwpuPtV7ax34Pqo9i8iUmgyMVmermgWEZGQkoKISJ5Ys31f5PtQUhARyRPPvr828n0oKYiI5AndT0FEREK6n4KIiISKMnDGVlIQEckTqimIiEhIfQoiIpJR2Zw6W0SkW6itb+R3b6xkSN8eHD2sLx+s3cVN547JdlgpKSmIiETs6ZlreOjtD5stO+vowZ3ejmWg/UjNRyIiEatrbGqxrLEL8xhloEtBSUFEJCu6MLedOppFRApAuoaSqqYgIlKounCGL1KfgohI/kt5LlfzkYhI95S+c7lqCiIiBam+qQujj1RTEBHJf6lO5vvrGjMfSAcoKYiIREyjj0REpE1daQpS85GISAFI18lcU2eLiBSorpzeVVMQESlQXbhMQUlBRKQQpJrd9LVFmzq/HTUfiYjkv1Sn8pc/+Ljz21FNQUQk/6XrZF5SpJqCiIgEiouiP2UrKYiI5Im8rymY2YVmttzMqszs5hTr/8nMtprZvODnn6OMR0QkG9J1Ki8ujj4pRHaPZjMrBh4AzgPWA7PNbJK7L0kq+ry73xBVHCIi2Zaueyvne03hdKDK3Ve5ex3wHDA+wv2JiOSkdHU0F+d5UjgMWJfwfH2wLNnXzWyBmf3ZzEZFGI+ISGReXbSJ7/5xdqT76N2jONLtQ7RJoSP3GvorUO7uJwJvAE+m3JDZBDOrNLPKrVu3pjlMEZGD94On5/DWsi0p16Xj+/2lJ47k+i8ek4YttS3KpLAeSPzmfziwIbGAu2939wPB00eBU1NtyN0fcfcKd68YOnRoJMGKiEQmDe1H/37hcfTuEVk3cCjKpDAbGGNmR5pZD+BKYFJiATMbmfD0MmBphPGIiOStTFzNDBGOPnL3BjO7AXgNKAaecPfFZvZLoNLdJwE3mtllQAOwA/inqOIREcln6RrB1J5I6yLuPgWYkrTstoTHtwC3RBmDiEi2peN0nqGKgq5oFhFJJ/eWk2Kn40t+ppqPlBREJGNq6xvZuvtA+wXzWDwnVO+vp3p/PZCeKa8zMW02KCmISAZ967FZnPbrN7IdRqTi9YST7nydk+58PW3bVU1BRArOnDU7sx1C5KJqPsrEFBegpCAiklapbrOZjtN5SQamzQYlBRGRtEpRUUiLkgzMkApKCiIiadUUUVbIxGR4oKQgIhK5dPQplBar+UhEJO+kqiikYzhphioKSgoi0nUPv/0h63bsY+H6al6YHZspv76xid++tpw9Bxpa/bude+u4d9oKmppankH/9N5qVmze3eq2Vm7ezVPvrW512+7OQ29/yPqd+1iwfhcvVK5LWe7vVdt4ddHGdl/jpupaHphehbuzsXo///232OMlG2p49v21Lcrf99ZKZq7a3nxhWi5eK4BpLkSyqanJ+cr97/KjL43hwhNGZDucgrOpupa7pi7jxTnrqdqyB4BvnDaKiR98zP3Tq9hb18DtXzk+5d/+fOIiJi/cyClHDOIfPtV85uNfvLKYIoNVd13CX1Js66L/mkFDk3P1meUpt72hupa7py7jL3M/ZnmQXL5R0fJWLd98bBYAq+++pM3Xed0zc5i7dhfnjR3O//nzAuav28X5Y0dw8X0zALjq9NHs2FsXln/wbx/y4N8+bHObuUw1BSlY++sbWbyhhp88Py/boRSkeIfq3qQawYGGpma/U9lXF/ubhsbUZeIViIbG2IPa+sZwXUOK2kWixuBv9tW3XlPpjL0HGoOYnP1B3I3txJAsU/MWpYOSghSs+Mc2U1eCSkx43Nso01pTSPKFX/F29KYUuSPVRWLwSbIqiuAfH99m8gij9vaUqaafdFBSkIIVP2nkz8exQHRgSGZrJ/TkxfGTcGOK8q3tJsqkED+5d7amkE+UFKRgfVJTUFrIhrYOe2u1uORv4EVFqb+Zt7YscXkUo3Xio0KTd93etQn59A5UUpCC5UGTQz59IAtBR75Dt/ZFO3n5J81HLf8gVe0hcRtRNh8l77u9ikM+fS9RUpCCFX57y6MPZD5KPjd/cthbP/CJzUeNTR42x7SoKYRt+C2bbOJFG5ucpiYPtxnfRuIVwO6eMrEk6kiTkLXSp9Bac1i47zxqbdKQ1Bw1/oH/oa6hiak/PjvboURuzpodfP3B93j1prM5bkT/Lm0jPk//qEN6h8tWBsMkd9c2UH7zZGb89IvN1qfy/acq+WDtLip//uVmy7/wm+ms3bGPk0cNZOL1Z3Uqtqsemcnmmlp69SimpLiIV64/i0UfV3Pp79/llevP4qRRAzu1vUyp+NU0tu2p4/5vjuPSEw9tsT5+ntu5r67Z8sff/QiAP81cQ0X5IMaffBgAJ97xWlhmxsptAOzaV8/Rtza7OWOo/ObJ4eNJ8zcwaf6GZuuP+8Wrbca/bNPu8PGRt8T2kWr46YrNuzn/3nfC509/77N8+/FZLcpd+LsZ4eN///OCZnE+dnVFq3HE950vVFPIUfPX7WLpxppsh5ERkxdsAuDd4ETRFT9+7gPO/s106oMhjrNX7+AbD7/XrMzcte1P2zxtyWa27Wl5E5i1O/YBMG/drk7H9t6q7azatpfFG2qYH/z9G0s3A/Dmsi2d3l6mbNsTO9k/PXNNyvXxb97JQ0/jxwrg929VhY9ralsOEc30DXemLmx5sdo7K7Y2e/7yB+vb3U78C0dc/P9ZCJQUJOviVfGD6RCevmxrs219tG1vizJRzV7ZFfETaqamLjgY7Y3yORit9QtEZdGG6nbLdCWkulaut8hHSgqSdZ7G0SLeRidjVLNXdkWUnaGZkqqdvK229VTiF5plSkMH9tfexXGp1LVxoV6+UVKQrIt/BtMxNfAnnYyt7ycXRDlsMlNSDxPt3Da6cgI+GPUdSArtdUin3q6SgkjaNKah+SiurW/gXfmwRyWMM4+zQqpaQXKiaK92lunaW0OqS6OTtDU9R2tUUxBJo3Q0HznNhyOmSjC51XwU3VW3mZIqxyYP62xvmGdHvrmnU0f2d6Chsd0yXdluvtCQ1Bz3+uJN7NpfT7+yEi76zEhq6xv53RsrOfWIQazfuY9rzzqSLbtref79dVx9ZjkDepfy29eWc8Vpoxh1SG+mLdnMOccOpbS4iGWbanj/ox3U7K/nGxWj+NqDf+eEQwewevtezjx6MFMXbmL4gJ4sWL+Ln15wHNeeVU7P0uIwlrlrd3LogF6MGNCTrbsP8Mq8j7noMyPZVF3Lsk01XHD8CJZv2s3w/j2ZsnAjN547hqYm555pK8J44rbtOcDrizdzWvkgNtfERqDcNWUZby7dwp2XHc/EDz5mzPC+XHjCSCZ+8DGPvLOKO8cfz2nlh7B4QzV9y0o4YnAfZq/ewbod+8IP5bhfTqNXaXHKaZvvn17FB2t3cdfXPsPMVdv5eNd+Fqyv5sU56/j5JWP59hlHhGVfmL2O7Xvr6FNW3GIU2B2TFrNrXx1LN+5mWP8yamobGNynB3UNTZhB/56lLN1Uw6qtezl0QM8WcXzj4fd4/6MdANw9dRm79tXzxtLN7NxbR/9epYwZ1pfXl8SOzZ4DjXx6ZD+OHtqXxRuqmbFyG585bAAfbt3DsSP6c+zwvvTrWUpJsXGgvgkH+pYV07O0mIG9e3DZSYeyauseVmzew6EDe7JhVy3njR1OcZHx4dY91Dc2cdyI/ry+eBMPv7OK6v311NY3sqXmk1FBsz7awfXPzGXBx7vYX9fEsH5l9CwtYu7aliOxPn1b82Gia7bvo/zmyfzz549M+f5+6O3MziY6fdkWbntlUbOmyreTRh/NCv43nVG5pvN/k6ussx1D2VZRUeGVlZXZDiNyiWO041bffQk/n7iQp2d+Mof7r796AndPXcbu2gYqjhjEv5z/Kb75aGyMdXy89XXnHM1PLzwu5TbbckXFKAb2KeWkwwdy0/PzqGtoorjIuPZz5bz8wcfNpgtOZfKNn+fDrXu58dkPAJh5y7k8NmMV89btonJN+8NDU1l99yXh6/j5JZ/mV5OXdnobIwf0ZGN1bYvlZrk1QikdykqKutQcIrnh0AE92VBdy/fPPpKfXTL2oLZlZnPcvfULKgKqKeSZ5KGWP/vLovDx8k27m52ot++Nfdtbt3N/l/a1aEM1izc0/5bc2OQ8Flyc1J6a/Q3sS/jG/pPn5/Fe8s1HDkJXEgKQMiFA4SUE6Fr7eFedN3Y405akHq+fKjmVD+7N6u2xaxqG9Svj8lMP56Nte7nitFFUlB9Ckzvu0LtHMfvrGykJvt3XNzolRUbP0mL21jVQUmSs2rqXX01ewu+uGEfvsmJKioxlm3Zz99RllBYbN3xxDONGD+RAQxOPzVhFj+Iirv5cefhF4KQ7Xwfg/VvPpay0mNJio8nhhNtjF9wtuON8isxocmfOmp1c+4fZHDu8Hy9d9zmKLBZTcZE1K19sRo/gdceXL//VhdQ3On16FHMg+JJVW99Ij5IiiswoLS6itr4xnBajrKSY+samjN2KE5QU8k57/WTpuO1fXEeG77XFrPmcL7VdaKvtLpb88gLG3hY7cbzxL1/gy/e806LMP558KBPnbWixPN0uOmEEUxfFLiiMXwGcWMtMvCr4kvtmhF8cHg2u6o2XHdi7lHm3nR+WveDed1i+eTfPTTiDM44a3KmYWjsp9u9ZCsAJhw3guQlnNlt3yuhBvPC/my/rWVrMv55/bKv7Gdi7Bz1KWu4rvh+APj1ip81+PUvoW5b6FJpYPjH2spJi4n8Sb5pNfm2JTbap1kdNHc15pq3RE03uYYdrOtR3YKRGWwrxm3dUEtu4W+t8ztRsr535v7VVtjgp3vh7sySHR1zlcmyZEmlSMLMLzWy5mVWZ2c0p1peZ2fPB+llmVh5lPIWgrVEO6R7zfbA1hWRKEq0rKfrko5jPI5IStTbcNh3Xo0Qln4cIp0tkScHMioEHgIuAscBVZpbcU/I9YKe7HwPcC/xHVPEUiraGVab7xh+t3Sqxo8zS25xVyBJPlNnOCZ2pbbZVMrmmEH8vZLo5RDonyv/O6UCVu69y9zrgOWB8UpnxwJPB4z8D55ruiNKm9moK6UwM9Qe5LXc0bXUXtJb3M3UoO9d81Hrh5BpBPNkUSk2oUEXZ0XwYsC7h+Xrgs62VcfcGM6sGBgNdny6zFW+v2Mqv/t+SdG82o8675+0WszMmu/XlheHjX0yMjUz66/wNLOvCjKsHO4Plv704v9nl/12ZYTTZefe8fdDbyHWtnTTLSjPzDbssqaMTWh+u26tHy7JxyZ2wQ/uVsWLznqzXhA5WvKKT3CFcKKJMCqn+9clvq46UwcwmABMARo8e3aVg+paVMGZ43y79bTbs2FvH9qTrAMYM78vIgb2aTfU7uE8PhvfvyZKNNZx6xCCG9y9jysJNHDWkD8eO6MfURZv40nHD6FlaxMbq2pQXdbXm7DFDeLdqG2NH9g9HmBwzrC9VW/Zw3Ih+LNu0m6OG9GFVMEz2+ENj5Ub078mmmlpOGjUAIIzn0IG9eLeqeb7v3aOYfXXNRyXFt53KmOF9w8RYWmwZu5J0WL8yrjx9NPe9ubLNcm3FDtCztIja+liiPH/scD41vB8XHD8CgO+ffSRrd+xj1CG9ePK7p1Ozv56epbEhifPX7+K6fziGspJituyupXxwH0YM6Mmdf13C2WOG8LflzS/AGtS7lJ376jv9Oo8b0Y87LzueL396GIf06REun3Lj2fzk+Xn8cvwJzco/8M1T+PqDf+e+q8aFy16+7nPc8MxcHrum+ZD42y49nmdmreGYYbn3OZx0w1nMX99yBtV7rziJ4f2bX4A4btQgfvSlY/hOwsWOcb+5/ETKB/dpufzrJ3LU0JbLc1FkF6+Z2ZnAHe5+QfD8FgB3vyuhzGtBmffMrATYBAz1NoLqLheviYikU0cvXouyPjobGGNmR5pZD+BKYFJSmUnANcHjy4G32koIIiISrciaj4I+ghuA14Bi4Al3X2xmvwQq3X0S8DjwJzOrAnYQSxwiIpIlkV7R7O5TgClJy25LeFwL/K8oYxARkY7TgGEREQkpKYiISEhJQUREQkoKIiISUlIQEZFQ3t15zcy2Amu6+OdDiGAKjTyjY6BjADoGcd3pOBzh7kPbK5R3SeFgmFllR67oK2Q6BjoGoGMQp+PQkpqPREQkpKQgIiKh7pYUHsl2ADlAx0DHAHQM4nQcknSrPgUREWlbd6spiIhIG7pNUjCzC81suZlVmdnN2Y4nSma22swWmtk8M6sMlh1iZtPMbGXwe1Cw3MzsvuC4LDCzU7IbfdeY2RNmtsXMFiUs6/RrNrNrgvIrzeyaVPvKVa0cgzvM7OPgvTDPzC5OWHdLcAyWm9kFCcvz9rNiZqPMbLqZLTWzxWb242B5t3ovHBR3L/gfYlN3fwgcBfQA5gNjsx1XhK93NTAkadlvgJuDxzcD/xE8vhiYSuwueGcAs7Idfxdf8xeAU4BFXX3NwCHAquD3oODxoGy/toM8BncA/5ai7Njgc1AGHBl8Porz/bMCjAROCR73A1YEr7VbvRcO5qe71BROB6rcfZW71wHPAeOzHFOmjQeeDB4/CfxjwvKnPGYmMNDMRmYjwIPh7u8QuydHos6+5guAae6+w913AtOAC6OPPj1aOQatGQ885+4H3P0joIrY5ySvPyvuvtHd5waPdwNLid0Lvlu9Fw5Gd0kKhwHrEp6vD5YVKgdeN7M5wf2tAYa7+0aIfXCAYcHyQj42nX3NhXosbgiaRp6IN5vQDY6BmZUD44BZ6L3QYd0lKViKZYU87Oosdz8FuAi43sy+0EbZ7nZsoPXXXIjH4kHgaOBkYCPwn8Hygj4GZtYXeAm4yd1r2iqaYlnBHIeu6C5JYT0wKuH54cCGLMUSOXffEPzeAvyFWJPA5nizUPB7S1C8kI9NZ19zwR0Ld9/s7o3u3gQ8Suy9AAV8DMyslFhCeMbdXw4Wd/v3Qkd1l6QwGxhjZkeaWQ9i94KelOWYImFmfcysX/wxcD6wiNjrjY+guAZ4JXg8Cbg6GIVxBlAdr2YXgM6+5teA881sUNDMcn6wLG8l9Q99ldh7AWLH4EozKzOzI4ExwPvk+WfFzIzYvd+Xuvs9Cau6/Xuhw7Ld052pH2KjDFYQG1nxs2zHE+HrPIrYiJH5wOL4awUGA28CK4PfhwTLDXggOC4LgYpsv4Yuvu5niTWP1BP7lve9rrxm4LvEOl2rgGuz/brScAz+FLzGBcROgCMTyv8sOAbLgYsSluftZwX4PLFmngXAvODn4u72XjiYH13RLCIioe7SfCQiIh2gpCAiIiElBRERCSkpiIhISElBRERCSgrSbZhZY8JsofPamwHUzH5gZlenYb+rzWxIF/7ugmCW00FmNuVg4xDpiJJsByCSQfvd/eSOFnb3h6IMpgPOBqYTm/30f7Ici3QTSgrS7ZnZauB54IvBom+6e5WZ3QHscfffmtmNwA+ABmCJu19pZocATxC7YHAfMMHdF5jZYGIXkg0ldpWwJezr28CNxKalngVc5+6NSfFcAdwSbHc8MByoMbPPuvtlURwDkTg1H0l30iup+eiKhHU17n46cD/wuxR/ezMwzt1PJJYcAO4EPgiW3Qo8FSy/HXjX3ccRu4p4NICZfRq4gtiEhSfwq6hcAAABhklEQVQDjcC3knfk7s/zyX0RPkNsaopxSgiSCaopSHfSVvPRswm/702xfgHwjJlNBCYGyz4PfB3A3d8ys8FmNoBYc8/XguWTzWxnUP5c4FRgdmyKHnrxycRsycYQm3oBoLfH7g0gEjklBZEYb+Vx3CXETvaXAb8ws+Npe3rlVNsw4El3v6WtQCx2C9UhQImZLQFGmtk84EfuPqPtlyFycNR8JBJzRcLv9xJXmFkRMMrdpwM/BQYCfYF3CJp/zOwcYJvH5u5PXH4Rsds5QmwitsvNbFiw7hAzOyI5EHevACYT60/4DbFJ6U5WQpBMUE1BupNewTfuuFfdPT4stczMZhH7onRV0t8VA08HTUMG3Ovuu4KO6D+Y2QJiHc3xqZnvBJ41s7nA28BaAHdfYmY/J3ZXvCJis5leD6xJEespxDqkrwPuSbFeJBKaJVW6vWD0UYW7b8t2LCLZpuYjEREJqaYgIiIh1RRERCSkpCAiIiElBRERCSkpiIhISElBRERCSgoiIhL6/3KG+bcg03RZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = maddpg_train()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
